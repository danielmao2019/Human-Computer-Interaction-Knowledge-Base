# [Papers][HCI] Virtual Reality (VR) <!-- omit in toc -->

## Table of Contents <!-- omit in toc -->

- [Unclassified](#unclassified)

----------------------------------------------------------------------------------------------------

## Unclassified

* [[Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges](https://arxiv.org/abs/2305.14080)]
    [[pdf](https://arxiv.org/pdf/2305.14080.pdf)]
    [[vanity](https://www.arxiv-vanity.com/papers/2305.14080/)]
    * Title: Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges
    * Year: 23 May `2023`
    * Authors: Efe Bozkir, Süleyman Özdel, Mengdi Wang, Brendan David-John, Hong Gao, Kevin Butler, Eakta Jain, Enkelejda Kasneci
    * Abstract: Latest developments in computer hardware, sensor technologies, and artificial intelligence can make virtual reality (VR) and virtual spaces an important part of human everyday life. Eye tracking offers not only a hands-free way of interaction but also the possibility of a deeper understanding of human visual attention and cognitive processes in VR. Despite these possibilities, eye-tracking data also reveal privacy-sensitive attributes of users when it is combined with the information about the presented stimulus. To address these possibilities and potential privacy issues, in this survey, we first cover major works in eye tracking, VR, and privacy areas between the years 2012 and 2022. While eye tracking in the VR part covers the complete pipeline of eye-tracking methodology from pupil detection and gaze estimation to offline use and analyses, as for privacy and security, we focus on eye-based authentication as well as computational methods to preserve the privacy of individuals and their eye-tracking data in VR. Later, taking all into consideration, we draw three main directions for the research community by mainly focusing on privacy challenges. In summary, this survey provides an extensive literature review of the utmost possibilities with eye tracking in VR and the privacy implications of those possibilities.
* [[Virtual, Augmented, and Mixed Reality for Human-Robot Interaction: A Survey and Virtual Design Element Taxonomy](https://arxiv.org/abs/2202.11249)]
    [[pdf](https://arxiv.org/pdf/2202.11249.pdf)]
    [[vanity](https://www.arxiv-vanity.com/papers/2202.11249/)]
    * Title: Virtual, Augmented, and Mixed Reality for Human-Robot Interaction: A Survey and Virtual Design Element Taxonomy
    * Year: 23 Feb `2022`
    * Authors: Michael Walker, Thao Phung, Tathagata Chakraborti, Tom Williams, Daniel Szafir
    * Abstract: Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI) has been gaining considerable attention in research in recent years. However, the HRI community lacks a set of shared terminology and framework for characterizing aspects of mixed reality interfaces, presenting serious problems for future research. Therefore, it is important to have a common set of terms and concepts that can be used to precisely describe and organize the diverse array of work being done within the field. In this paper, we present a novel taxonomic framework for different types of VAM-HRI interfaces, composed of four main categories of virtual design elements (VDEs). We present and justify our taxonomy and explain how its elements have been developed over the last 30 years as well as the current directions VAM-HRI is headed in the coming decade.
